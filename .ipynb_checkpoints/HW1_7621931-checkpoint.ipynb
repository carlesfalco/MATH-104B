{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carles Falc√≥ i Gandia\n",
    "\n",
    "Perm Number: 7621931\n",
    "\n",
    "falcoigandia@ucsb.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import zeros, array\n",
    "from math import factorial, sin\n",
    "from pandas import DataFrame\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced system\n",
    "where floating point numbers are represented as $x = \\pm S\\cdot 2^E$ with $S = (1.b_1b_2)_2$ and $E\\in\\{-1,0,1\\}$.\n",
    " \n",
    "(a) Using basic principle of counting we see that there are:\n",
    "* 2 ways of choosing the sign\n",
    "* $2^2$ ways of choosing the mantissa\n",
    "* 3 ways of choosing the exponent\n",
    "\n",
    "Then a total of $2\\cdot 2^2\\cdot 3 = 24$ numbers can be represented.\n",
    "\n",
    "(b) The following code allows us to represent them in the real line easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5   -0.625 -0.75  -0.875  0.5    0.625  0.75   0.875 -1.    -1.25  -1.5\n",
      " -1.75   1.     1.25   1.5    1.75  -2.    -2.5   -3.    -3.5    2.     2.5\n",
      "  3.     3.5  ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAACcCAYAAAAkuKk9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHABJREFUeJzt3XvYZXVd9/H3hxkFBGTEQQ4DOpqk\nopjUBPVEOQoImjp0KU+kKZVE9Fx4uDRTwyARfFA8ZflkJCTmYfKQRomiiJNpogyHRERyPCDDGQFh\nlDTg+/yx1q1rNvdx7j33vvfi/bqufbHXYa/f97e+a2/W916/tSZVhSRJkiSpf7YZdQCSJEmSpK3D\ngk+SJEmSesqCT5IkSZJ6yoJPkiRJknrKgk+SJEmSesqCT5IkSZJ6yoJPkhaZJFckWb0VtvvJJEcP\naVsrk1SSpcPY3jAl+b0kX5hi2WZxD3OfTNLWvknWb41tz9Duy5LclGRTkh3a/u61Fdr5+SS3D3u7\n85XkgiS/Peo45irJY5PcvUBtfWJr/MZIWpws+CQtmCTfTXJXeyJ6Q5L3JNlx1HENU9vHQ+aw/nuS\nnNKdV1WPr6p1w46tqp5eVWdvyWfn2q9xMZ99MguvB94M0B7zE697O9+DTUmeP6wGk+wAvBH49ara\nEbhniNu+IclBE9NV9V9VtWxY2x+WqnpqVf3jbNZNcmGS393aMS1CbwROHXUQkhaGBZ+khfas9kT0\nScD+wGu2RiNJlmyN7WrrW4xXDecqyR7AU4CPA1TVjhMv4Hu034P29f4hNr0HsKSqrhriNjVmZvEd\n+ndg7yT7LUQ8kkbLgk/SSFTVDcB5NIUfAEm2TfLmJN9LcmOSdyXZvl22OsnGJH+W5Jb2itPzO599\nT5K/SXJukh8CT5lhe8uT/GuS25PcmuTfk2zTLtszyUeT3JzkO0le0mnnL5J8KMl7k9zZDr9c1S77\nB+DhwL+0V27+tJ3/4fbqyA+SfD7J49v5xwLPB/60Xf9f2vk/vZrW9uHtSa5rX29Psu3APnlFO4Tv\n+iS/P9U+T7IuyTHt+99L8oV2/9zW9vPpU3xu0n61nt/u31uSnND5zDZJXp3kW0m+3+6zXabY/kQ/\nXpXkBuDv2/nPTHJZm6P/SPLEzmcmtn1nkq8n+a2p+j2dueyTJDsnObPdz9cmOWWaPywcClxSVf89\nyzi2T/LOdtsbk5ye5AHtsg1JDu2su117LD1uYBv7Af8JLGnz9MlJ2tklyQc6x/afJkm77LHt/ri1\nXX52kp3aZR8GHgZ8ut32SzIwBDHN1bKT2v/ekea7+JDO8mPaY+Xmtt3NrhgOxLk2yV8l+Vyb488m\nWdFZ/uQkl7T74cIkvzwQx++2749rP/uO9jj6Vue79Rbgl4F3t316yyRxPDbJ3Ul+v83LzUleORDn\nazvThyfZ0Jm+IcnL0/xObErzG7VHks+0++hTSR480OZx7XFwXZIXd+YvSfLnSb6d5vv2/iTLBuL8\nwyTXAOemGc67ts3n7Um+PJGPqirg34BnTLb/JfWLBZ+kkUhzT9HTgQ2d2W8Efp6mCHw0sAI4sbN8\nd2B5O/9o4Iwkj+ksfx7NMKWdgC/MsL1XABuBXYHdgD8DKk3R9y80J84rgIOBlyU5rNPOs4G1wDLg\nHOCvAarqBWx+9eZN7fqfBPahOWG+BHh/u/4Z7fs3tes/a5JddQLwK20ffgE4AHhtZ/nuwM5trC8C\n3tk9yZ7BgcBVNPv0TcCZEyf/XdP0C+Ag4DE0++nEThHyEuAI4MnAnsBtwDuniWV3YBfgEcCxSX4R\nOAv4I+ChwN8C56QtdoFvAb/e9v11wPvSXFWbr+n2ydnA3TTH0v7A04BjptjOfu12Zut1wBPbz/0S\nsBqYKKzfC3SHHa4B/quqruxuoKoubz97T5unyQr4dwEPAB5JU5T+Mc33ZsLJNLnYjyavJ7TbPhK4\nCXhau+13TNGP59H8EWMPmu/HSwGSPAl4K/C/gb3a1/Ip90bjBTTfy12Bb9Lsf5I8jOY7ehrNsfEu\nmgJn5ym28xvA+nbdvwbe3fbpFcBFwDFtn14xxeeXAKto8v4M4NQkj5oh9q7fovke7AscBfwz8HKa\n350daXLQbetXgUcBvwm8rlMUv5LmmDuIZv/9D/C2gc8eSJO3NTTH5lKa34blwPHATzrrX0nzmyKp\n76rKly9fvhbkBXwX2ATcCRTwWWBZuyzAD4Gf66z/q8B32veraU62d+gs/xDw5+379wDv7SybaXsn\n05x4PXogxgOB7w3Mew3w9+37vwDO7yzbF7hroI+HTLMPlrV937kT9ymT7KdD2vffAp7RWXYY8N3O\nPrkLWNpZfhPwK1O0vY7m5Bbg94ANnWUPauPafZrcHdKZXtmuv1dn3leAo9r3VwIHd5btQXOCunSS\nba+mORHdrjPvb4DXD6x3FfDkKeK7DFjT6dsXplhvIu6lc9knNCfnPwa27yz/HeBzU7Tzd8Bps9mX\n7bxrgad2ptcA3+jE/APgQe30vwIvmWLbjwXu7kxvN5EnYFuae/oe1Vn+UuBTU2zrKOBLnekbgIOm\naetC4E860y8HPt6+fwPtd6idfjBwb3d7A22vBd7Tmd6l7ceuwB8Cnx9Y/9LOsXch8Lvt++OAr02y\nnWWD606zPwtY3pn3VeCITpyv7Sw7fOAYugF4Tmf6E8DbOtOvBNYOtLWys/wdwDvb998Bfq2z7JHA\nj2h+6yY+u2dn+f+huYr3hCn69mLg3Kn67suXr/68xv4+CUlj54iqOj/Jk4EP0Pzl+XaaE7kHARd3\nLjKF5q/WE26rqh92pq+muXo04ZrO+5m2dzpN8fbpdvkZVXUazRWmPbP50weX0NzzMuGGzvsfAdsl\nWVpV93nCXpohf6cCR7Yx3dsuWk5zEj+TPdt+Thjs8/cH2v0RzVWD2fhpP6rqR+1+mOtDdAb3xcTn\nHwF8LMm9neX30BRO106ynZtr8+GPjwCO7g5pAx5I2/ckL6QpKFa2y3Zk5itGszHVPtmF5srY9Z3j\naRs2P+a6bqO50jyj9gri7tw3zyvaOL6b5FJgTZLzgacCfzDL/nTt3sb8vcnaSbIn8JfA/2pj3wa4\nfo5tTHU87Nltt6ruSDLT8f/TfVtVtybZ1G5n8DuxWT9mERNtXLN9wug9VXXLwDbm8j25sfP+rkmm\nB7fVPaauBg5qj5G9aa5kVmf5NjRXLgHurarrOsvOpMn5R9I8HOu9NH8gm3iQz07Mfh9IGmMO6ZQ0\nElX1bzRXt97czrqF5uTn8VW1rH3tXM1DLiY8JM1TCCc8HOie4HRPhKbdXlXdWVWvqKpHAc8CXp7k\nYJqTre90PrOsqnaqqtne61ID08+juVpzCM3ww5Xt/Eyx/qDraIqfCYN9XigzxTnoGuDpA/txu6qa\nrNibbPvXAKcOfP5BVfXBJI+guYJ2PPDQap4U+TV+tk+3hmtorvAt78Tz4Kp6/BTrf5VmOPGMqqpo\nipLBPHf31dk0wzqPAi6oqpvm2oG2jXvbbU/Wzuk0V8WfUFUPphkS2N2ncz0Guq6nucoIQHvf2lRD\nMCfs3Vl/F5rC6Hru+52A++6v2ZpPn6DZXw/qTO8+z+1Bp9+03/f2GJm4Cjz4nZooRjfrS1X9uKpO\nrKrH0gxrPZLm+JnwOJqh65J6zoJP0ii9HTg0yZOq6l6ak/i3tffokGTFwL1z0NzT8sAkvw48E/jw\nZBueaXtpHgjy6PYv53fQXH26h2ZY4h1pHiCyffughCd0Hwoxgxtp7r+ZsBNNofB9mhPDN8yw/qAP\nAq9NsmuS5TT3IL5vlrEM00xxDnoXzb1OjwBo418zh8//HXBckgPT2CHJb6Z5iMgONCe3N7fb/n3g\nCXPY9pxV1fXAp4G3JHlwmofS/Fx7pXoynwF+Mcl2s2zig8BJSR7aHq8nsHmeP0Jz79Yf01yp2ZI+\n/Bj4GPCGdn/+HM2Qzol2dqIZcn1HkofTXEHtmusx0PUh4DlJfjnJA2mGVN87w2fWtPnfFjiFZvjs\nTTT3ze6f5LlJlrZXex8OfGoL4ppPn6AZSvzMJMvSPFTmxTN9YBZOan97foHmPsaJf2LiXcBpSfaG\n5l7GJJPd90u7/JA0/xbkNjS/cXfT/jMd7e/eb9DcXyyp5yz4JI1MVd1MO8yonfUqmoe4XJjkDuB8\nmgcQTLiBZqjcdTQPOzmuqr4xTRPTbW+fdnoT8CXg/1XVuna407NoHpLyHZorhe9m5qsRE/4vTYF2\ne5I/aft3Nc1f579Oc89Q15nAvu36H59ke6fQPHDiq8DlNA99OWWS9ba2wX7N5C9pTsw/neROmn4f\nONvGqmo9zb1af02T8w0099hRVV8H3kKTtxtpHjDyxVn3ZMu9kGZY6dfbmD5Cc2/ifVTVjcAFNFd3\nZ+PEdrtX0BQRX6R5aMzE9u6keVDJCpr9uqX+qP3v1W1876Z9iFAbw0E0Q40/Bnx04LOn0hTxtyc5\nfi6NVtWlNPerfYzmu3B9286Pp/nY+2gezHILzdWoo9tt3Ujz4KQTaP6QcjzwzKrakuGJbwNemOap\nrG+ace37Oovm2Pwezb2VH9yCbXTdA3yZ5rfnU8DJVfX5dtmbaH6zLmi/U/8B/OI021pBc5/ynTRX\nwM+lKbyhyfO1VfXVecYraQykGSUgSYtbktXA+6pqr5nWlRaDJPvSDMU8oIbwP9skbwAeVlVTPRl0\nbLRPkr2V5iEj97lPMMlamoetjOKPG72X5F+Bt1bVBaOORdLW50NbJEnaCtorkbMdCjytJLvSXOE8\nYhjbG4Ukz6YZ6rqE5p9o+PJkxZ62vqp65qhjkLRwHNIpSdIi1g6f/C7w4ar6yojDmY8jaYZlb6QZ\nbvj80YYjSfcPDumUJEmSpJ7yCp8kSZIk9ZQFnyRJkiT11Fg+tGX58uW1cuXKUYdxv/HDH/6QHXbY\nYeYVtWiYs/FjzsaL+Ro/5my8mK/xY84W3sUXX3xLVe0603pjWfCtXLmS9evXjzqM+41169axevXq\nUYehOTBn48ecjRfzNX7M2XgxX+PHnC28JFfPZj2HdEqSJElST1nwSZIkSVJPWfBJkiRJUk9Z8EmS\nJElST1nwSZIkSVJPWfBJkiRJUk9Z8EmSJElST1nwSZIkSVJPWfBJkiRJUk9Z8EmSJElST1nwSZIk\nSVJPWfBJkiRJUk9Z8EmSJElSTw2l4EtyeJKrkmxI8upJlm+b5B/b5V9OsrKdf2iSi5Nc3v73qcOI\nR5IkSZI0hIIvyRLgncDTgX2B30my78BqLwJuq6pHA28D3tjOvwV4VlXtBxwN/MN845EkSZIkNYZx\nhe8AYENVfbuqfgKsBdYMrLMGOLt9/xHg4CSpqkur6rp2/hXAdkm2HUJMkiRJknS/N4yCbwVwTWd6\nYztv0nWq6m7gB8BDB9Z5DnBpVf14CDFJkiRJ0v3e0iFsI5PMq7msk+TxNMM8nzZlI8mxwLEAu+22\nG+vWrZtzoNoymzZtcn+PGXM2fszZeDFf48ecjRfzNX7M2eI1jIJvI7B3Z3ov4Lop1tmYZCmwM3Ar\nQJK9gI8BL6yqb03VSFWdAZwBsGrVqlq9evUQQtdsrFu3Dvf3eDFn48ecjRfzNX7M2XgxX+PHnC1e\nwxjSeRGwT5JHJnkgcBRwzsA659A8lAXgucAFVVVJlgGfAF5TVV8cQiySJEmSpNa8C772nrzjgfOA\nK4EPVdUVSU5O8ux2tTOBhybZALwcmPinG44HHg38eZLL2tfD5huTJEmSJGk4QzqpqnOBcwfmndh5\n/9/AkZN87hTglGHEIEmSJEna3FD+4XVJkiRJ0uJjwSdJkiRJPWXBJ0mSJEk9ZcEnSZIkST1lwSdJ\nkiRJPWXBJ0mSJEk9ZcEnSZIkST1lwSdJkiRJPWXBJ0mSJEk9ZcEnSZIkST1lwSdJkiRJPWXBJ0mS\nJEk9ZcEnSZIkST1lwSdJkiRJPWXBJ0mSJEk9ZcEnSZIkST1lwSdJkiRJPWXBJ0mSJEk9ZcEnSZIk\nST1lwSdJkiRJPWXBJ0mSJEk9ZcEnSZIkST1lwSdJkiRJPWXBJ0mSJEk9ZcEnSZIkST1lwSdJkiRJ\nPWXBJ0mSJEk9laqa/0aSw4G/BJYA766q0waWbwu8F/gl4PvAb1fVd9tlrwFeBNwDvKSqzpupvVWr\nVtX69evnHfewfPzSazn9vKu47va72HPZ9rzysMdwxP4rRh3WvE3066i972TtNTv1pl9gzobZ1kLs\nw7621W1vLjnb0hi35HML2dY4WbduHatXrx51GEOz0HkexbHo7+J4teW5x/joa87GIV9JLq6qVTOt\nt3QIDS0B3gkcCmwELkpyTlV9vbPai4DbqurRSY4C3gj8dpJ9gaOAxwN7Aucn+fmqume+cS2Uj196\nLa/5p8u563+akK+9/S5e80+XAyy6g2IuNuvX3v3pF5izobeFbQ2lvVnmbEtj3JLPLWRbGp2FzvPI\njkV/F8erLc89xkJfc9a3fA1jSOcBwIaq+nZV/QRYC6wZWGcNcHb7/iPAwUnSzl9bVT+uqu8AG9rt\njY3Tz7vqpwfDhLv+5x5OP++qEUU0HH3tF/S3bwvZL9saXXtbGuNib0ujs9B57uuxaFvj1dZC62vf\n7Nd4mPeQziTPBQ6vqmPa6RcAB1bV8Z11vtaus7Gd/hZwIPAXwIVV9b52/pnAJ6vqI5O0cyxwLMBu\nu+32S2vXrp1X3MNy+bU/mHLZfit2XsBIhqvbr922hxvv+tmyce4XmLNhtzXItrasvdnmbEtj3JLP\nLWRb42bTpk3suOOOow5jKBY6z6M6Fv1dHK+2PPcYD33N2bjk6ylPecqshnQOo+A7EjhsoOA7oKpe\n3FnninadbsF3AHAy8KWBgu/cqvrodG0upnv4fu20C7j29rvuM3/Fsu354qufOoKIhqPbr1fsdzdv\nubwZ/Tvu/QJzNuy2umxry9ubbc62NMYt+dxCtjVu+nQP30LneVTHor+L49WW5x7joa85G5d8zfYe\nvmEM6dwI7N2Z3gu4bqp1kiwFdgZuneVnF7VXHvYYtn/Aks3mbf+AJbzysMeMKKLh6Gu/oL99W8h+\n2dbo2tvSGBd7Wxqdhc5zX49F2xqvthZaX/tmv8bDvB/aAlwE7JPkkcC1NA9hed7AOucARwNfAp4L\nXFBVleQc4ANJ3krz0JZ9gK8MIaYFM3Hj5mJ/is9cdfsFd7KiJ/0Cczbstrb2PuxrW4PtzTZnWxrj\nlnxuIdvS6Cx0nkd1LPq7OF5tee4xHvqas77la1j/LMMzgLfT/LMMZ1XVqUlOBtZX1TlJtgP+Adif\n5sreUVX17fazJwB/ANwNvKyqPjlTe4tpSOf9QZ+GLt1fmLPxY87Gi/kaP+ZsvJiv8WPOFt6C/bMM\nAFV1LnDuwLwTO+//Gzhyis+eCpw6jDgkSZIkST8zjHv4JEmSJEmLkAWfJEmSJPWUBZ8kSZIk9ZQF\nnyRJkiT1lAWfJEmSJPWUBZ8kSZIk9ZQFnyRJkiT1lAWfJEmSJPWUBZ8kSZIk9ZQFnyRJkiT1lAWf\nJEmSJPWUBZ8kSZIk9ZQFnyRJkiT1lAWfJEmSJPWUBZ8kSZIk9ZQFnyRJkiT1lAWfJEmSJPWUBZ8k\nSZIk9ZQFnyRJkiT1lAWfJEmSJPWUBZ8kSZIk9ZQFnyRJkiT1lAWfJEmSJPWUBZ8kSZIk9ZQFnyRJ\nkiT1lAWfJEmSJPXUvAq+JLsk+UySb7b/fcgU6x3drvPNJEe38x6U5BNJvpHkiiSnzScWSZIkSdLm\n5nuF79XAZ6tqH+Cz7fRmkuwCnAQcCBwAnNQpDN9cVY8F9gd+LcnT5xmPJEmSJKk134JvDXB2+/5s\n4IhJ1jkM+ExV3VpVtwGfAQ6vqh9V1ecAquonwCXAXvOMR5IkSZLUmm/Bt1tVXQ/Q/vdhk6yzArim\nM72xnfdTSZYBz6K5SihJkiRJGoKlM62Q5Hxg90kWnTDLNjLJvOpsfynwQeAdVfXtaeI4FjgWYLfd\ndmPdunWzbF7ztWnTJvf3mDFn48ecjRfzNX7M2XgxX+PHnC1eMxZ8VXXIVMuS3Jhkj6q6PskewE2T\nrLYRWN2Z3gtY15k+A/hmVb19hjjOaNdl1apVtXr16ulW1xCtW7cO9/d4MWfjx5yNF/M1fszZeDFf\n48ecLV7zHdJ5DnB0+/5o4J8nWec84GlJHtI+rOVp7TySnALsDLxsnnFIkiRJkgbMt+A7DTg0yTeB\nQ9tpkqxK8m6AqroVeD1wUfs6uapuTbIXzbDQfYFLklyW5Jh5xiNJkiRJas04pHM6VfV94OBJ5q8H\njulMnwWcNbDORia/v0+SJEmSNATzvcInSZIkSVqkLPgkSZIkqacs+CRJkiSppyz4JEmSJKmnLPgk\nSZIkqacs+CRJkiSppyz4JEmSJKmnLPgkSZIkqacs+CRJkiSppyz4JEmSJKmnLPgkSZIkqacs+CRJ\nkiSppyz4JEmSJKmnLPgkSZIkqadSVaOOYc6S3AxcPeo47keWA7eMOgjNiTkbP+ZsvJiv8WPOxov5\nGj/mbOE9oqp2nWmlsSz4tLCSrK+qVaOOQ7NnzsaPORsv5mv8mLPxYr7GjzlbvBzSKUmSJEk9ZcEn\nSZIkST1lwafZOGPUAWjOzNn4MWfjxXyNH3M2XszX+DFni5T38EmSJElST3mFT5IkSZJ6yoJPs5Lk\n9Um+muSyJJ9OsueoY9L0kpye5Btt3j6WZNmoY9LUkhyZ5Iok9ybxKWeLWJLDk1yVZEOSV486Hk0v\nyVlJbkrytVHHopkl2TvJ55Jc2f4mvnTUMWl6SbZL8pUk/9nm7HWjjkmbc0inZiXJg6vqjvb9S4B9\nq+q4EYelaSR5GnBBVd2d5I0AVfWqEYelKSR5HHAv8LfAn1TV+hGHpEkkWQL8F3AosBG4CPidqvr6\nSAPTlJL8BrAJeG9VPWHU8Wh6SfYA9qiqS5LsBFwMHOF3bPFKEmCHqtqU5AHAF4CXVtWFIw5NLa/w\naVYmir3WDoB/KVjkqurTVXV3O3khsNco49H0qurKqrpq1HFoRgcAG6rq21X1E2AtsGbEMWkaVfV5\n4NZRx6HZqarrq+qS9v2dwJXAitFGpelUY1M7+YD25XniImLBp1lLcmqSa4DnAyeOOh7NyR8Anxx1\nEFIPrACu6UxvxJNRaatIshLYH/jyaCPRTJIsSXIZcBPwmaoyZ4uIBZ9+Ksn5Sb42yWsNQFWdUFV7\nA+8Hjh9ttIKZc9aucwJwN03eNEKzyZcWvUwyz79kS0OWZEfgo8DLBkYZaRGqqnuq6kk0o4kOSOLw\n6UVk6agD0OJRVYfMctUPAJ8ATtqK4WgWZspZkqOBZwIHlzfsjtwcvmNavDYCe3em9wKuG1EsUi+1\n94F9FHh/Vf3TqOPR7FXV7UnWAYcDPihpkfAKn2YlyT6dyWcD3xhVLJqdJIcDrwKeXVU/GnU8Uk9c\nBOyT5JFJHggcBZwz4pik3mgfAHImcGVVvXXU8WhmSXadeBJ4ku2BQ/A8cVHxKZ2alSQfBR5D8xTB\nq4Hjqura0Ual6STZAGwLfL+ddaFPVl28kvwW8FfArsDtwGVVddhoo9JkkjwDeDuwBDirqk4dcUia\nRpIPAquB5cCNwElVdeZIg9KUkhwE/DtwOc05B8CfVdW5o4tK00nyROBsmt/EbYAPVdXJo41KXRZ8\nkiRJktRTDumUJEmSpJ6y4JMkSZKknrLgkyRJkqSesuCTJEmSpJ6y4JMkSZKknrLgkyRJkqSesuCT\nJEmSpJ6y4JMkSZKknvr/CksRY2asv8UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21c9c6c5d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying numbers in real line\n",
    "# INPUT: S,E,sign\n",
    "# OUPTUT: plot\n",
    "# Carles Falc√≥ i Gandia\n",
    "# 12/01/19\n",
    "\n",
    "S = ['00','01','10','11']\n",
    "E = [-1,0,1]\n",
    "sign = [-1,1]\n",
    "dec = []\n",
    "for e in E:\n",
    "    for i in sign:\n",
    "        for s in S:\n",
    "            dec.append(i*(1+int(s[0])/2+int(s[1])/4)*2**e)\n",
    "dec = array(dec)\n",
    "print(dec)\n",
    "plt.figure(figsize = (15,2))\n",
    "plt.scatter(dec,zeros(dec.size))\n",
    "plt.grid()\n",
    "plt.title('Representation in the real line (Toy floating point numbers)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see they're not uniformly distributed.\n",
    "\n",
    "(c) The machine precision of this reduced system is $\\epsilon =2^{-2} = 0.25$. Note that $1+\\epsilon$ is precisely the smallest number greater than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many numbers are there in double precision?\n",
    "\n",
    "Following the same idea as before, there are:\n",
    "* 2 ways of choosing the sign\n",
    "* $2^{52}$ ways of choosing the mantissa\n",
    "* 11 bits for the exponent $\\implies$ $2^{11}$ ways of choosing the exponent\n",
    "\n",
    "By principle of counting there should be $2\\cdot2^{52}\\cdot 2^{11} = 2^{64} = 18446744073709551616$ numbers in double precision.\n",
    "However, according \"Numerical computing with IEEE floating point arithmetic\" by M. Overton, the IEEE double format uses two different representations for the number $0$ - $-0$ and $+0$. If we understand the question as \"how many different numbers are there...\" we should exclude one. Also we might not consider NaN and the infinities as numbers. These are represented by fixing to 1 all bits in the exponent. Then there are a total of $2^{64-11} = 2^{53}$ of these \"numbers\". In conclusion, with these considerations we can represent:\n",
    "$$2^{64}-2^{53} -1 = 18428729675200069631$$\n",
    "different numbers in the IEEE double precision format.\n",
    "\n",
    "# Arithmetic with only two digits using rounding\n",
    "$x = 2.5$ and $y=2.4$. Then we have:\n",
    "$$(x-y)^2 = \\text{round}(0.01) = 0.0$$\n",
    "but also $$x^2+y^2-2xy=\\text{round}(6.25)+\\text{round}(5.76)-12 = 6.3 + 5.8-12 = 0.1$$ while the actual value should be $(x-y)^2 = 0.01$.\n",
    "\n",
    "# Computing $x-\\sin(x)$\n",
    "for small $x$. We'll have digits cancellation since $\\sin(x)\\approx x $ for small $x$. First, we can estimate the number of bits we lose in the following way. Imagine that we have $y,x$ with $x>y$ and we find positive integers $p,q$ such that:\n",
    "$$2^{-q} \\leq 1-\\frac{y}{x}\\leq 2^{-p}$$\n",
    "Now let's write the floating point representation of $y,x$:\n",
    "$$x = S_1\\cdot2^{E_1}$$\n",
    "$$y = S_2\\cdot2^{E_2}$$ where the two mantissas are greater or equal than 1 and less than 2. Since $x>y$, $E_1>E_2$ and we can rewrite $y = (S_2\\cdot2^{E_2-E_1})\\cdot2^{E_1}$. Taking the difference we see that:\n",
    "$$x-y = (S_1-S_2\\cdot2^{E_2-E_1})\\cdot 2^{E_1}$$ Note that this mantissa\n",
    "$$(S_1-S_2\\cdot2^{E_2-E_1}) = S_1\\Big(1-\\frac{S_2\\cdot2^{E_2}}{S_2\\cdot2^{E_2}}\\Big) = S_1\\Big(1-\\frac{y}{x}\\Big)$$ is greater than $2^{-q}$ and less than $2^{-p}$. This means that in order to have a normalized representation of the number $x-y$ we should shift the exponent at least $p$ and at most $q$ digits. This means that at least $p$ bits and at most $q$ bits are lost when shifting the exponent.\n",
    "\n",
    "In our case we have that $\\tfrac{\\sin(x)}{x}>0.99958\\Leftrightarrow 1-\\tfrac{\\sin(x)}{x} < 0.00042 < 2^{-11}$. Similarly $\\tfrac{\\sin(x)}{x}<0.9996\\Leftrightarrow 1-\\tfrac{\\sin(x)}{x} > 0.0004> 2^{-12}$. Then according with what we've seen we have that at least we're losing 11 bits of accuracy and at most 12 bits. We'll use the second part of this problem to estimate the relative error we make in this computation.\n",
    "\n",
    "Another way to compute the difference $x-\\sin(x)$ is by using the Taylor expansion at $a=0$ for $$\\sin(x) = x-\\frac{x^3}{3!}+\\frac{x^5}{5!}+\\ldots$$\n",
    "A common expression for the remainder of $f(x) = x-\\sin(x)$ is $$R_k(x)=\\frac{f^{k+1)}(\\eta)}{(k+1)!}x^{k+1}$$ with $\\eta\\in(0,x)$. The derivatives of $f$ are bounded by 1 and then the error we make by using a Taylor expansion is always less than the quantity: $$\\frac{|x|^{k+1}}{(k+1)!}$$\n",
    "If $x$ is small enough we don't need a lot of terms in the Taylor expansion to ensure that the error we make is less than $\\epsilon$ or at least similar. The following code illustrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Testing for x = 0.1000\n",
      "The needed degree for the desired accuracy is: 9\n",
      "The aproximated value of x-sin(x) is: 0.0001665833531718\n",
      "- Testing for x = 0.0500\n",
      "The needed degree for the desired accuracy is: 8\n",
      "The aproximated value of x-sin(x) is: 0.0000208307293217\n",
      "- Testing for x = -0.0500\n",
      "The needed degree for the desired accuracy is: 8\n",
      "The aproximated value of x-sin(x) is: -0.0000208307293217\n",
      "- Testing for x = 0.0050\n",
      "The needed degree for the desired accuracy is: 5\n",
      "The aproximated value of x-sin(x) is: 0.0000000208333073\n",
      "- Testing for x = 0.0001\n",
      "The needed degree for the desired accuracy is: 3\n",
      "The aproximated value of x-sin(x) is: 0.0000000000001667\n"
     ]
    }
   ],
   "source": [
    "# Truncated Taylor series of x-sin(x)\n",
    "# INPUT: x, k (degree)\n",
    "# OUTPUT: approx x-sin(x)\n",
    "# Carles Falc√≥ i Gandia\n",
    "# 14/01/2019\n",
    "\n",
    "def sin_taylor(x,k):\n",
    "    return sum([(-1)**(j/2+1/2)*x**j/factorial(j) for j in range(3,k+1,2)])\n",
    "\n",
    "# Estimating needed degree\n",
    "# INPUT: x\n",
    "# OUTPUT: needed degree\n",
    "# Carles Falc√≥ i Gandia\n",
    "# 14/01/2019\n",
    "\n",
    "tol = 2**(-52) # nearly full machine precision\n",
    "t_max = 30 # limit in time s\n",
    "\n",
    "def needed_degree(x):\n",
    "    tic = time()\n",
    "    x = abs(x)\n",
    "    k = 1\n",
    "    while(abs(x)**(k+1)/factorial(k+1) > tol and time() - tic < t_max):\n",
    "        k += 1\n",
    "    return k\n",
    "\n",
    "# Testing for x = 0.05, -0.05, 0.005, 0.0001\n",
    "l = [0.1,0.05,-0.05,0.005,0.0001]\n",
    "for k in l:\n",
    "    print(\"- Testing for x = %.4f\" % k)\n",
    "    print(\"The needed degree for the desired accuracy is: %i\" % needed_degree(k))\n",
    "    print(\"The aproximated value of x-sin(x) is: %.16f\" % sin_taylor(k,needed_degree(k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only a few terms in the Taylor expansion are needed to achieve nearly full machine precision as $x$ becomes smaller. With this, we can estimate the relative error we make when doing $x-\\sin(x)$ for small values of $x$. This relative error will be given by:\n",
    "$$\\big|\\frac{y-fl(y)}{y}\\big|$$ where $y = x-\\sin(x)$. We'll compute the relative error for the values of $x = 0.05,0.005,0.0005,2^{-15},2^{-30}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$x$</th>\n",
       "      <th>Relative eror</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>2.223434e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.000000e-03</td>\n",
       "      <td>1.477428e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.000000e-04</td>\n",
       "      <td>1.093470e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.051758e-05</td>\n",
       "      <td>2.384186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.980232e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            $x$  Relative eror\n",
       "0  5.000000e-02   2.223434e-13\n",
       "1  5.000000e-03   1.477428e-11\n",
       "2  5.000000e-04   1.093470e-08\n",
       "3  3.051758e-05   2.384186e-07\n",
       "4  2.980232e-08   1.000000e+00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing relative errors\n",
    "# INPUT: x\n",
    "# OUTPUT: relative errors\n",
    "# Carles Falc√≥ i Gandia\n",
    "# 15/01/2019\n",
    "\n",
    "z = [0.05,0.005,0.0005,2**(-15),2**(-25)]\n",
    "\n",
    "def rel(y,fl_y):\n",
    "    return abs((y-fl_y)/y)\n",
    "\n",
    "rel_errors = [rel(i-sin(i),sin_taylor(i,needed_degree(i))) for i in z]\n",
    "\n",
    "data = {'$x$':z,'Relative eror':rel_errors}\n",
    "DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first relative errors may seem acceptable, note that when $x = 2^{-25}$ the digits cancellation leads to a relative error of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $y= \\sqrt{1+x} -1$ for small $x$\n",
    "\n",
    "(a) First we see that it can be written as:\n",
    "$$y= \\sqrt{1+x} -1 = \\sqrt{1+x} -1\\frac{\\sqrt{1+x} +1}{\\sqrt{1+x} +1} = \\frac{x}{\\sqrt{1+x} +1}$$\n",
    "\n",
    "(b) When substracting two numbers that are really close in magnitude a cancellation of digits occurs. Let's see this. Imagine that $x,y$ have different sign and $x+y\\approx 0$ or at least, its sum it's close to 0. If $fl(x)$ is the floating point representation of $x$ and we assume that their sum is computed exactly we have:\n",
    "$$fl(x)+fl(y) = x(1+\\delta_x) + y(1+\\delta_y) = (x+y) + (x\\delta_x + y\\delta_y)$$ with $|\\delta_x|,|\\delta_y| < \\epsilon$.\n",
    "Then the relative error we make when adding is:\n",
    "$$\\big|\\frac{x+y -fl(x)-fl(y)}{x+y}\\big| = \\big|\\frac{x\\delta_x}{x+y}+\\frac{y\\delta_y}{x+y}\\big|$$ which becomes large as $x+y\\approx 0$. This is exactly what happens with $y$ when $x$ is small. However by rewriting $y$ in the way we did we avoid having to compute the difference between two close numbers in magnitude and thus, this cancellation of digits.\n",
    "\n",
    "# Machine precision\n",
    "\n",
    "By running the program we see that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine precision eps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine precision\n",
    "# 14/01/2019\n",
    "\n",
    "a = 4/3\n",
    "b = a - 1\n",
    "c = b + b + b\n",
    "eps0 = abs(c - 1)\n",
    "print(\"Machine precision eps\")\n",
    "eps0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
